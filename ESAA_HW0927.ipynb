{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOO2rhMECvlCExGqOnH96dH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whyeon92/ESAA_OB/blob/Code_Study/ESAA_HW0927.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.1 í…ìŠ¤íŠ¸ ë¶„ì„ ì´í•´  "
      ],
      "metadata": {
        "id": "smFlsUQQfVvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[ì§„í–‰ í”„ë¡œì„¸ìŠ¤]**\n",
        " 1. í…ìŠ¤íŠ¸ ì‚¬ì „ ì¤€ë¹„ ì‘ì—…, ì „ì²˜ë¦¬  \n",
        "   : í…ìŠ¤íŠ¸ë¥¼ í”¼ì²˜ë¡œ ë§Œë“¤ê¸° ì „ í´ë Œì§•, ëŒ€/ì†Œë¬¸ì ë³€ê²½, íŠ¹ìˆ˜ë¬¸ì ì‚­ì œ, ë‹¨ì–´ í† í°í™”, ì˜ë¯¸ ì—†ëŠ” ë‹¨ì–´(Stop Word) ì œê±°, ì–´ê·¼ ì¶”ì¶œ ë“±ì˜ í…ìŠ¤íŠ¸ ì •ê·œí™” ì‘ì—…\n",
        " 2. í”¼ì²˜/ë²¡í„°í™” ì¶”ì¶œ  \n",
        "   : ê°€ê³µëœ í…ìŠ¤íŠ¸ì—ì„œ í”¼ì²˜ ì¶”ì¶œ, í•´ë‹¹ í”¼ì²˜ì— ë²¡í„° ê°’ í• ë‹¹   \n",
        "    â†’ BOW, Word2Vec ì´ìš©\n",
        " 3. ML ëª¨ë¸ ìˆ˜ë¦½ ë° í•™ìŠµ/ì˜ˆì¸¡/í‰ê°€  \n",
        "   : í”¼ì²˜ ë²¡í„°í™”ëœ ë°ì´í„° ì„¸íŠ¸ì— ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì ìš©"
      ],
      "metadata": {
        "id": "pDZzK7ypfbiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.2 í…ìŠ¤íŠ¸ ì‚¬ì „ ì¤€ë¹„ ì‘ì—…(í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬) - í…ìŠ¤íŠ¸ ì •ê·œí™”"
      ],
      "metadata": {
        "id": "QGM5kLNiEmWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë¬¸ì¥ í† í°í™”"
      ],
      "metadata": {
        "id": "NTeLNOqKIFSv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29IyyIcPEhFf",
        "outputId": "9d77647c-4b40-40d4-ea3e-ea103305c25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 3\n",
            "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"
          ]
        }
      ],
      "source": [
        "from nltk import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "text_sample = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
        "               You can see it out your window or on your television. \\\n",
        "               You feel it when you go to work, or go to church or pay your taxes.'\n",
        "sentences = sent_tokenize(text=text_sample)\n",
        "print(type(sentences),len(sentences))\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë‹¨ì–´ í† í°í™”"
      ],
      "metadata": {
        "id": "-wytSbqFIG92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "sentence = 'The Matrix is everywhere its all around us, here even in this room.'\n",
        "words = word_tokenize(sentence)\n",
        "print(type(words), len(words))\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eopP-Fg1G6MU",
        "outputId": "ab3204b8-3e12-49a4-e6b7-bcfd95d69521"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 15\n",
            "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, sent_tokenize\n",
        "\n",
        "#ì—¬ëŸ¬ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ ëœ ì…ë ¥ ë°ì´í„°ë¥¼ ë¬¸ì¥ë³„ë¡œ ë‹¨ì–´ í† í°í™” ë§Œë“œëŠ” í•¨ìˆ˜ ìƒì„±\n",
        "def tokenize_text(text):\n",
        "\n",
        "    #ë¬¸ì¥ë³„ë¡œ ë¶„ë¦¬ í† í°\n",
        "    sentences = sent_tokenize(text)\n",
        "    #ë¶„ë¦¬ëœ ë¬¸ì¥ë³„ ë‹¨ì–´ í† í°í™”\n",
        "    word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
        "    return word_tokens\n",
        "\n",
        "#ì—¬ëŸ¬ ë¬¸ì¥ë“¤ì— ëŒ€í•´ ë¬¸ì¥ë³„ ë‹¨ì–´ í† í°í™” ìˆ˜í–‰\n",
        "word_tokens = tokenize_text(text_sample)\n",
        "print(type(word_tokens),len(word_tokens))\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGl1Kt15HABH",
        "outputId": "dd0040ae-56e3-42c6-8129-59d12f91e83f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 3\n",
            "[['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.'], ['You', 'can', 'see', 'it', 'out', 'your', 'window', 'or', 'on', 'your', 'television', '.'], ['You', 'feel', 'it', 'when', 'you', 'go', 'to', 'work', ',', 'or', 'go', 'to', 'church', 'or', 'pay', 'your', 'taxes', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ìŠ¤íƒ‘ì›Œë“œ ì œê±°"
      ],
      "metadata": {
        "id": "AlQPldzUIB03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8rWd_SjHJjB",
        "outputId": "94b89346-daf1-457a-8abe-cdaa77295314"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('ì˜ì–´ stop words ê°œìˆ˜:',len(nltk.corpus.stopwords.words('english')))\n",
        "print(nltk.corpus.stopwords.words('english')[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZxIe_7mHKOV",
        "outputId": "76e83a45-c59b-4167-9748-dd8c8ec9fbc8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì˜ì–´ stop words ê°œìˆ˜: 179\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "all_tokens = []\n",
        "#ìœ„ ì˜ˆì œì—ì„œ 3ê°œì˜ ë¬¸ì¥ë³„ë¡œ ì–»ì€ word_tokens list ì— ëŒ€í•´ ìŠ¤í†± ì›Œë“œë¥¼ ì œê±°í•˜ëŠ” ë°˜ë³µë¬¸\n",
        "for sentence in word_tokens:\n",
        "    filtered_words=[]\n",
        "    #ê°œë³„ ë¬¸ì¥ë³„ë¡œ í† í°í™”ëœ ë¬¸ì¥ listì— ëŒ€í•´ ìŠ¤í†± ì›Œë“œë¥¼ ì œê±°í•˜ëŠ” ë°˜ë³µë¬¸\n",
        "    for word in sentence:\n",
        "        #ì†Œë¬¸ìë¡œ ëª¨ë‘ ë³€í™˜\n",
        "        word = word.lower()\n",
        "        #í† í°í™”ëœ ê°œë³„ ë‹¨ì–´ê°€ ìŠ¤í†± ì›Œë“œì˜ ë‹¨ì–´ì— í¬í•¨ë˜ì§€ ì•Šìœ¼ë©´ word_tokensì— ì¶”ê°€\n",
        "        if word not in stopwords:\n",
        "            filtered_words.append(word)\n",
        "    all_tokens.append(filtered_words)\n",
        "\n",
        "print(all_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg6xuXHwHM1P",
        "outputId": "283b19f6-4ca4-4823-a143-86712c177720"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.'], ['see', 'window', 'television', '.'], ['feel', 'go', 'work', ',', 'go', 'church', 'pay', 'taxes', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemmingê³¼ Lemmatization"
      ],
      "metadata": {
        "id": "mjiyxChhIz3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))\n",
        "print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))\n",
        "print(stemmer.stem('happier'),stemmer.stem('happiest'))\n",
        "print(stemmer.stem('fancier'),stemmer.stem('fanciest'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqeMy3HGHSPO",
        "outputId": "fc84e635-90d0-407b-a0d3-afc3cedbecf9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "work work work\n",
            "amus amus amus\n",
            "happy happiest\n",
            "fant fanciest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemma = WordNetLemmatizer()\n",
        "print(lemma.lemmatize('amusing','v'),lemma.lemmatize('amuses','v'),lemma.lemmatize('amused','v'))\n",
        "print(lemma.lemmatize('happier','a'),lemma.lemmatize('happiest','a'))\n",
        "print(lemma.lemmatize('fancier','a'),lemma.lemmatize('fanciest','a'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBwe1E_0HSNL",
        "outputId": "51b3eae7-7e4c-43b2-cb5a-8c68229f512c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amuse amuse amuse\n",
            "happy happy\n",
            "fancy fancy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[í´ë Œì§•]**  \n",
        " í…ìŠ¤íŠ¸ì—ì„œ ë¶„ì„ì— ì˜¤íˆë ¤ ë°©í•´ê°€ ë˜ëŠ” ë¶ˆí•„ìš”í•œ ë¬¸ìë“¤ì„ ì‚¬ì „ì— ì œê±°\n",
        "\n",
        "**[í† í°í™”]**  \n",
        " í…ìŠ¤íŠ¸ë¥¼ ë‹¨ìœ„ì— ë”°ë¼ ë‚˜ëˆ„ëŠ” ì‘ì—….\n",
        " - ë¬¸ì¥ í† í°í™” : ë¬¸ì¥ì˜ ë§ˆì¹¨í‘œ, ê°œí–‰ë¬¸ì ë“± ë¬¸ì¥ì˜ ë§ˆì§€ë§‰ì„ ëœ»í•˜ëŠ” ê¸°í˜¸ë¡œ ë¬¸ì¥ì„ ë‚˜ëˆ„ê¸°\n",
        " - ë‹¨ì–´ í† í°í™” : ë¬¸ì¥ì„ ë‹¨ì–´ë¡œ í† í°í™”. ê¸°ë³¸ì ìœ¼ë¡œ ê³µë°±ì„ ë‹¨ìœ„ë¡œ ë‹¨ì–´ë¥¼ ë¶„ë¦¬  \n",
        "\n",
        "âš ï¸ ë¬¸ì¥ì„ ë‹¨ì–´ë³„ë¡œ í•˜ë‚˜ì”© í† í°í™”í•  ê²½ìš° ë¬¸ë§¥ì  ì˜ë¯¸ê°€ ì‚¬ë¼ì§!  \n",
        "â†’ n-gramìœ¼ë¡œ í•´ê²°  \n",
        " n-gram: ë‹¨ì–´ë¥¼ í•˜ë‚˜í•˜ë‚˜ í† í°í™”í•˜ëŠ” ê²Œ ì•„ë‹Œ nê°œì˜ ë‹¨ì–´ë¥¼ í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ ìƒê°í•˜ì—¬ í† í°í™”!\n",
        "\n",
        "**[ìŠ¤í†±ì›Œë“œ ì œê±°]**  \n",
        " ìŠ¤í†±ì›Œë“œ: ë¶„ì„ì— í° ì˜ë¯¸ë¥¼ ê°–ì§€ ì•ŠëŠ” beë™ì‚¬, ê´€ì‚¬ ë“±ì˜ ë‹¨ì–´  \n",
        " ì¦‰, í•„ìˆ˜ ë¬¸ë²•ì  ìš”ì†Œì§€ë§Œ ë¬¸ë§¥ì ìœ¼ë¡œ í° ì˜ë¯¸ê°€ ì—†ëŠ” ë‹¨ì–´  \n",
        " ì˜¤íˆë ¤ ì¤‘ìš”í•œ ë‹¨ì–´ë¡œ ì¸ì§€ë˜ë©´ ì•ˆë˜ëŠ”ë° ìì£¼ ë‚˜ì™€ì„œ ê·¸ë ‡ê²Œ í•´ì„ë  ìˆ˜ ìˆê¸°ì— ì œê±° í•„ìˆ˜  \n",
        " â†’ nltkì˜ ìŠ¤í†±ì›Œë“œ ëª©ë¡ì—ì„œ í•„í„°ë§!\n",
        "\n",
        "**[Stemming / Lemmatization]**  \n",
        " ë‘˜ ë‹¤ ë‹¨ì–´ì˜ ì›í˜•ì¸ ì–´ê·¼ì„ ë§¤í•‘  \n",
        "- Stemming  \n",
        " : ì¼ë°˜ì ì¸ ë°©ë²•, ë” ë‹¨ìˆœí™”ëœ ë°©ë²•ì„ ì‚¬ìš©í•´ì„œ ì² ìê°€ í›¼ì†ëœ ê²½ìš°ê°€ ì¦ìŒ!\n",
        "- Lemmatization\n",
        " : ë¬¸ë²•ì  ìš”ì†Œì™€ ë” ì˜ë¯¸ì ì¸ ë¶€ë¶„ì„ ì°¾ì•„ì¤˜ì„œ ì˜¤ëœì‹œê°„ì´ ê±¸ë¦¬ì§€ë§Œ ë” ê¹”ë”í•œ ì²˜ë¦¬"
      ],
      "metadata": {
        "id": "ykj79fGoenHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.3 Bag of Words - BOW"
      ],
      "metadata": {
        "id": "LDHh26WDJA3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "dense = np.array([[3, 0, 1], [0, 2, 0 ]])"
      ],
      "metadata": {
        "id": "2QyMJSStHSJC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse\n",
        "\n",
        "#0ì´ ì•„ë‹Œ ë°ì´í„° ì¶”ì¶œ\n",
        "data = np.array([3,1,2])\n",
        "\n",
        "#í–‰ ìœ„ì¹˜ì™€ ì—´ ìœ„ì¹˜ë¥¼ ê°ê° ë°°ì—´ë¡œ ìƒì„±\n",
        "row_pos = np.array([0,0,1])\n",
        "col_pos = np.array([0,2,1])\n",
        "\n",
        "#sparse íŒ¨í‚¤ì§€ì˜ coo_matrixë¥¼ ì´ìš©í•˜ì—¬ COO í˜•ì‹ìœ¼ë¡œ í¬ì†Œ í–‰ë ¬ ìƒì„±\n",
        "sparse_coo = sparse.coo_matrix((data, (row_pos,col_pos)))"
      ],
      "metadata": {
        "id": "MVvYhGIrHSG5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_coo.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkSyd9FWHSAz",
        "outputId": "79288540-6eec-44b4-bea9-a4f5b88a9172"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 0, 1],\n",
              "       [0, 2, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse\n",
        "\n",
        "dense2 = np.array([[0,0,1,0,0,5],\n",
        "                    [1,4,0,3,2,5],\n",
        "                    [0,6,0,3,0,0],\n",
        "                    [2,0,0,0,0,0],\n",
        "                    [0,0,0,7,0,8],\n",
        "                    [1,0,0,0,0,0]])\n",
        "\n",
        "#0ì´ ì•„ë‹Œ ë°ì´í„° ì¶”ì¶œ\n",
        "data2 = np.array([1, 5, 1, 4, 3, 2, 5, 6, 3, 2, 7, 8, 1])\n",
        "\n",
        "#í–‰ ìœ„ì¹˜ì™€ ì—´ ìœ„ì¹˜ë¥¼ ê°ê° arrayë¡œ ìƒì„±\n",
        "row_pos = np.array([0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 4, 4, 5])\n",
        "col_pos = np.array([2, 5, 0, 1, 3, 4, 5, 1, 3, 0, 3, 5, 0])\n",
        "\n",
        "#COO í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "sparse_coo = sparse.coo_matrix((data2, (row_pos,col_pos)))\n",
        "\n",
        "#í–‰ ìœ„ì¹˜ ë°°ì—´ì˜ ê³ ìœ í•œ ê°’ë“¤ì˜ ì‹œì‘ ìœ„ì¹˜ ì¸ë±ìŠ¤ë¥¼ ë°°ì—´ë¡œ ìƒì„±\n",
        "row_pos_ind = np.array([0, 2, 7, 9, 10, 12, 13])\n",
        "\n",
        "#CSR í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "sparse_csr = sparse.csr_matrix((data2, col_pos, row_pos_ind))\n",
        "\n",
        "print('COO ë³€í™˜ëœ ë°ì´í„°ê°€ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ ë‹¤ì‹œ Denseë¡œ ì¶œë ¥ í™•ì¸')\n",
        "print(sparse_coo.toarray())\n",
        "print('CSR ë³€í™˜ëœ ë°ì´í„°ê°€ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ ë‹¤ì‹œ Denseë¡œ ì¶œë ¥ í™•ì¸')\n",
        "print(sparse_csr.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j0mB7bHHR-2",
        "outputId": "e98bcc0c-c421-47c4-d47e-ac54b0b07ad2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COO ë³€í™˜ëœ ë°ì´í„°ê°€ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ ë‹¤ì‹œ Denseë¡œ ì¶œë ¥ í™•ì¸\n",
            "[[0 0 1 0 0 5]\n",
            " [1 4 0 3 2 5]\n",
            " [0 6 0 3 0 0]\n",
            " [2 0 0 0 0 0]\n",
            " [0 0 0 7 0 8]\n",
            " [1 0 0 0 0 0]]\n",
            "CSR ë³€í™˜ëœ ë°ì´í„°ê°€ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ ë‹¤ì‹œ Denseë¡œ ì¶œë ¥ í™•ì¸\n",
            "[[0 0 1 0 0 5]\n",
            " [1 4 0 3 2 5]\n",
            " [0 6 0 3 0 0]\n",
            " [2 0 0 0 0 0]\n",
            " [0 0 0 7 0 8]\n",
            " [1 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dense3 = np.array([[0,0,1,0,0,5],\n",
        "             [1,4,0,3,2,5],\n",
        "             [0,6,0,3,0,0],\n",
        "             [2,0,0,0,0,0],\n",
        "             [0,0,0,7,0,8],\n",
        "             [1,0,0,0,0,0]])\n",
        "\n",
        "coo = sparse.coo_matrix(dense3)\n",
        "csr = sparse.csr_matrix(dense3)"
      ],
      "metadata": {
        "id": "Hs9KpXxKHR8o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Bag of Words]**  \n",
        ": ë¬¸ì„œê°€ ê°€ì§€ëŠ” ëª¨ë“  ë‹¨ì–´ë¥¼ ë¬¸ë§¥, ìˆœì„œë¥¼ ë¬´ì‹œí•˜ê³  ì¼ê´„ì ìœ¼ë¡œ ë‹¨ì–´ì— ëŒ€í•´ ë¹ˆë„ ê°’ì„ ë¶€ì—¬í•´ í”¼ì²˜ ê°’ì„ ì¶”ì¶œí•˜ëŠ” ëª¨ë¸  \n",
        "\n",
        " - ğŸ¥°ì‰½ê³  ë¹ ë¥´ê²Œ êµ¬ì¶• ê°€ëŠ¥, ê·¸ëƒ¥ ê°„ë‹¨íˆ ë‹¨ì–´ í† í°í™”í•˜ê³  íšŸìˆ˜ ì„¸ê¸°\n",
        " - ğŸ¥°í™œìš©ë„ê°€ ë†’ìŒ\n",
        "\n",
        " - ğŸ¤¢ë¬¸ë§¥ ì˜ë¯¸ë¥¼ ë„ˆë¬´ ë°˜ì˜ ëª»í•¨\n",
        " - ğŸ¤¢í¬ì†Œ í–‰ë ¬ ë¬¸ì œ  \n",
        "    : ë¬¸ì„œë§ˆë‹¤ ì„œë¡œ ë‹¤ë¥¸ ë‹¨ì–´ë¡œ êµ¬ì„±ë˜ì–´ì„œ BOWì˜ ë‹¨ì–´ ì¤‘ í•´ë‹¹ ë¬¸ì„œì— ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ë‹¨ì–´ê°€ ë” ë§ì„ ìˆ˜ ìˆìŒ. ê·¸ëŸ° ê²½ìš° í–‰ë ¬ì´ ëŒ€ë¶€ë¶„ì˜ ê°’ì´ 0ìœ¼ë¡œ ì±„ì›Œì§€ëŠ” í¬ì†Œí–‰ë ¬ì´ ë˜ëŠ”ë°, ì´ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì˜ ìˆ˜í–‰ì‹œê°„ê³¼ ì˜ˆì¸¡ì„±ëŠ¥ì„ ë–¨ì–´ëœ¨ë¦¬ê¸° ë•Œë¬¸ì— ë‚˜ì˜ë‹¤!  \n",
        "\n",
        "**[ë²¡í„° í”¼ì²˜í™”]**  \n",
        " BOWì—ì„œ ë²¡í„° í”¼ì²˜í™” â†’ ëª¨ë“  ë¬¸ì„œì—ì„œ ëª¨ë“  ë‹¨ì–´ë¥¼ ì¹¼ëŸ¼ í˜•íƒœë¡œ ë‚˜ì—´í•˜ê³  ê° ë‹¨ì–´ì˜ íšŸìˆ˜(ë˜ëŠ” ì •ê·œí™”ëœ ë¹ˆë„)ë¥¼ ê°’ìœ¼ë¡œ ë¶€ì—¬í•˜ëŠ” ë°ì´í„° ì„¸íŠ¸ ëª¨ë¸ë¡œ ë³€ê²½ â†’ Mê°œì˜ í…ìŠ¤íŠ¸ë¬¸ì„œì™€ Nê°œì˜ ë‹¨ì–´ â†’ M*Ní˜•íƒœì˜ í–‰ë ¬ êµ¬ì„±  \n",
        " - ì¹´ìš´íŠ¸ ê¸°ë°˜ ë²¡í„°í™”  \n",
        "  â†’ ì¹´ìš´íŠ¸ íšŸìˆ˜ê°€ ë§ìœ¼ë©´ ì¤‘ìš”í•˜ë‹¤! ê·¸ëŸ¬ë‚˜ ì´ëŸ´ ê²½ìš° ë¬¸ì„œì˜ íŠ¹ì§•ì„ ë‚˜íƒ€ë‚´ê¸° ë³´ë‹¨ ì–¸ì–´ì˜ íŠ¹ì„±ìƒ ë¬¸ì¥ì— ìì£¼ ì‚¬ìš©ë  ìˆ˜ ë°–ì— ì—†ëŠ” ë‹¨ì–´ë„ ë†’ì€ ê°’ì´ ë¶€ì—¬ë  ê°€ëŠ¥ì„±ì´ ì¡´ì¬.\n",
        " - TF-IDF ê¸°ë°˜ ë²¡í„°í™”  \n",
        "   â†’ ê°œë³„ ë¬¸ì„œì—ì„œ ìì£¼ ë‚˜íƒ€ë‚˜ëŠ” ë‹¨ì–´ì— ë†’ì€ ê°€ì¤‘ì¹˜, ê·¸ëŸ¬ë‚˜ ëª¨ë“  ë¬¸ì„œì— ìì£¼ ë‚˜íƒ€ë‚˜ëŠ” ë‹¨ì–´ì—” í˜ë„í‹°ë¥¼ ì¤˜ì„œ ìœ„ì˜ ì¹´ìš´íŠ¸ ê¸°ë°˜ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ë‹¨ì ì„ ì–´ëŠì •ë„ ì™„í™”."
      ],
      "metadata": {
        "id": "is7P88DYa9mP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EAcXYxBMIrGU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}